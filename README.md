# Local-Agent RAG con ChromaDB, LangChain y Ollama

Este repositorio muestra cÃ³mo montar un pipeline de **Retrieval-Augmented Generation (RAG)** usando:

- **Python 3.12.x**  
- **uv** como gestor de entornos y dependencias  
- **ChromaDB** para vector search local  
- **LangChain** para orquestar embeddings y chains  
- **Ollama** como LLM y proveedor de embeddings

## ðŸ“ DescripciÃ³n del Proyecto

Este proyecto implementa un asistente basado en RAG que responde preguntas sobre localidades en MedellÃ­n, Colombia. La aplicaciÃ³n:

1. **Carga datos locales** sobre comunas y municipios (nombre, Ã¡rea, poblaciÃ³n, comida favorita, puntos de interÃ©s, ingresos)
2. **Utiliza embeddings** para convertir texto en vectores mediante el modelo `mxbai-embed-large`
3. **Almacena los datos en ChromaDB** como base de datos vectorial local
4. **Recupera informaciÃ³n relevante** cuando el usuario hace preguntas especÃ­ficas sobre las localidades
5. **Genera respuestas contextualizadas** usando el LLM `llama3.2`

Todo funciona de manera local y sin conexiÃ³n a internet gracias a Ollama.

> **Nota**: Este repositorio es una adaptaciÃ³n del tutorial presentado en [este video de Tech With Tim](https://www.youtube.com/watch?v=E4l91XKQSgw&t=502s&ab_channel=TechWithTim).

---

## ðŸ“‹ Requisitos

- **Python â‰¥ 3.12, < 4.0**  
- **curl** (para instalar uv)  
- **Git** (para clonar el repositorio)

---

## âš™ï¸ InstalaciÃ³n de `uv`

Sigue la guÃ­a oficial de uv: https://docs.astral.sh/uv/#getting-started  

### macOS / Linux

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Una vez que `uv` estÃ© instalado y disponible en tu terminal, puedes navegar al directorio raÃ­z del curso y ejecutar:

```bash
# Primero crea el entorno virtual con Python 3.12
uv venv --python 3.12

# Luego instala las dependencias desde uv.lock
uv sync
```

Esto:

* Crea un entorno virtual .venv/ con Python 3.12.x
* Instala las mismas versiones bloqueadas en uv.lock

Para activar el ambiente virtual:

```bash
# En macOS o Linux
source .venv/bin/activate

# En Windows
# .venv\Scripts\activate
```

Una vez activado, verÃ¡s el nombre del entorno (.venv) al inicio de tu lÃ­nea de comandos.

Recuerda siempre usar `uv` antes de `pip install`.

## ðŸ§© Componentes Principales

### 1. Vector Search con ChromaDB

La bÃºsqueda vectorial se implementa localmente usando ChromaDB, permitiendo:
- Convertir texto a vectores (embeddings)
- Almacenar eficientemente estos vectores
- Buscar informaciÃ³n por similitud semÃ¡ntica

### 2. Pipeline RAG

El sistema utiliza un pipeline RAG (Retrieval-Augmented Generation) compuesto por:

- **Retrieval**: Recupera documentos relevantes usando similaridad de embeddings
  - Utiliza `mxbai-embed-large` para generar representaciones vectoriales
  - Almacena y consulta vectores en ChromaDB
  - Configura un retriever para devolver los 5 documentos mÃ¡s similares

- **Augmentation**: Enriquece la consulta del usuario con el contexto recuperado
  - Formatea los documentos recuperados para insertarlos en el prompt

- **Generation**: Genera respuestas usando el LLM
  - Utiliza el modelo `llama3.2` para crear respuestas naturales
  - Incorpora el contexto recuperado para responder con precisiÃ³n

## ðŸš€ Uso de la AplicaciÃ³n

Una vez configurado el entorno, ejecuta:

```bash
python main.py
```

La aplicaciÃ³n mostrarÃ¡ un prompt donde podrÃ¡s preguntar sobre las diferentes localidades de MedellÃ­n, por ejemplo:
- "Â¿CuÃ¡l es la comida favorita en Robledo?"
- "Â¿QuÃ© lugares turÃ­sticos hay en El Poblado?"
- "Â¿CuÃ¡l es el ingreso promedio en Envigado?"

La aplicaciÃ³n recuperarÃ¡ los documentos relevantes y generarÃ¡ una respuesta basada en los datos disponibles.